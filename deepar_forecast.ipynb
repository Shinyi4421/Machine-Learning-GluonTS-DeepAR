{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c90e1-3890-4900-b60e-0bbb94d681c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This project uses GluonTS, a Python toolkit for probabilistic time series modeling.\n",
    "# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "# You may not use this file except in compliance with the License.\n",
    "# A copy of the License is located at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# or in the \"license\" file accompanying this file. This file is distributed \n",
    "# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \n",
    "# either express or implied. See the License for the specific language \n",
    "# governing permissions and limitations under the License.\n",
    "\n",
    "import torch\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Set PyTorch Matmul precision\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# File path settings\n",
    "train_pkl_path = 'F:/DeepAR_models/Data_clean/gluonts_listDataset_deepar_validation_dataframe.pkl'\n",
    "model_load_path = 'F:/DeepAR_models/Model'  \n",
    "output_csv_path = 'F:/DeepAR_models/Data_Plotly/forecast_results_all.csv'\n",
    "\n",
    "# Create CSV file\n",
    "def save_forecasts_to_csv(forecasts, tss, output_path):\n",
    "    forecast_data = []\n",
    "    for i, (forecast, series) in enumerate(zip(forecasts, tss)):\n",
    "        for j in range(len(forecast.samples[0])):\n",
    "            forecast_data.append({\n",
    "                \"item_id\": i,\n",
    "                \"date\": (series.index[-1] + j + 1).to_timestamp(),\n",
    "                \"forecast_mean\": forecast.mean[j],\n",
    "                \"forecast_quantile_0.1\": forecast.quantile(0.1)[j],\n",
    "                \"forecast_quantile_0.9\": forecast.quantile(0.9)[j]\n",
    "            })\n",
    "\n",
    "    forecast_df = pd.DataFrame(forecast_data)\n",
    "    forecast_df.to_csv(output_path, index=False)\n",
    "    print(f\"Forecast results have been saved to {output_path}\")\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_index = torch.cuda.current_device() if torch.cuda.is_available() else None\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available, using device: {torch.cuda.get_device_name(device_index)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU\")\n",
    "\n",
    "# Set GPU memory usage fraction to 90%\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.set_per_process_memory_fraction(0.9, device_index)\n",
    "\n",
    "# Data loading\n",
    "def load_pkl(pkl_path):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        return pd.read_pickle(f)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_data = load_pkl(train_pkl_path)\n",
    "\n",
    "# Set up PyTorch DataLoader, enable multi-threaded data loading\n",
    "def from_gluonts(dataset):\n",
    "    for entry in dataset:\n",
    "        target = torch.tensor(entry['target'].tolist(), dtype=torch.float).to(device)\n",
    "        feat_dynamic_real = torch.tensor(entry['feat_dynamic_real'], dtype=torch.float).to(device)\n",
    "        yield target, feat_dynamic_real  # Return target and feat_dynamic_real to ensure data is moved to the GPU\n",
    "\n",
    "train_loader = DataLoader(from_gluonts(train_data), batch_size=512, num_workers=8)\n",
    "\n",
    "# Check current free and total GPU memory\n",
    "if device.type == 'cuda':\n",
    "    free_memory, total_memory = torch.cuda.mem_get_info(device_index)\n",
    "    print(f\"Free memory: {free_memory / 1024**2:.2f} MB, Total memory: {total_memory / 1024**2:.2f} MB\")\n",
    "\n",
    "# Load pre-trained model\n",
    "print(\"Loading model from disk...\")\n",
    "try:\n",
    "    predictor = PyTorchPredictor.deserialize(Path(model_load_path))\n",
    "    print(\"Model loaded and moved to GPU.\")\n",
    "\n",
    "    print(\"Starting prediction...\")\n",
    "    forecast_it, ts_it = make_evaluation_predictions(dataset=train_data, predictor=predictor, num_samples=100)\n",
    "    print(\"Prediction completed.\")\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    print(f\"Generated {len(forecasts)} forecast results.\")\n",
    "\n",
    "    for i, (forecast, series) in enumerate(zip(forecasts, tss)):\n",
    "        print(f\"Forecast result {i+1}:\")\n",
    "        print(f\"Actual data:\\n{series}\")\n",
    "        print(f\"Forecast mean: {forecast.mean}\")\n",
    "        print(f\"Number of forecast samples: {len(forecast.samples)}\")\n",
    "        print(f\"90% confidence interval: {forecast.quantile(0.1)}, {forecast.quantile(0.9)}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Independent CSV generation process\n",
    "    save_forecasts_to_csv(forecasts, tss, output_csv_path)\n",
    "    \n",
    "    # Start evaluating forecast results\n",
    "    print(\"Starting evaluation of forecast results...\")\n",
    "    evaluator = Evaluator()\n",
    "    try:\n",
    "        for _ in tqdm(range(1), desc=\"Evaluating forecast results\"):\n",
    "            agg_metrics, item_metrics = evaluator(tss, forecasts)\n",
    "        print(\"Evaluation completed.\")\n",
    "\n",
    "        print(\"Aggregate metrics:\")\n",
    "        for key, value in agg_metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred during evaluation: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An exception occurred during prediction or evaluation: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
