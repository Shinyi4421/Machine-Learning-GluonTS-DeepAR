{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e1627-d5c1-4e5e-bb50-b5f84610526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This project uses GluonTS, a Python toolkit for probabilistic time series modeling.\n",
    "# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "# You may not use this file except in compliance with the License.\n",
    "# A copy of the License is located at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# or in the \"license\" file accompanying this file. This file is distributed \n",
    "# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \n",
    "# either express or implied. See the License for the specific language \n",
    "# governing permissions and limitations under the License.\n",
    "\n",
    "# This file uses the GluonTS library for probabilistic time series modeling.\n",
    "# See https://github.com/awslabs/gluonts for more information.\n",
    "\n",
    "import torch\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Set PyTorch Matmul precision\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# File path settings\n",
    "train_pkl_path = 'F:\\\\DeepAR_models\\\\Data_clean\\\\gluonts_listDataset_deepar_train_dataframe_final_2015_2023.pkl'\n",
    "model_save_path = 'F:\\\\DeepAR_models\\\\Model'\n",
    "output_csv_path = 'F:\\\\DeepAR_models\\\\forecast_results_train.csv'\n",
    "\n",
    "# Create CSV file\n",
    "def save_forecasts_to_csv(forecasts, tss, output_path):\n",
    "    forecast_data = []\n",
    "    for i, (forecast, series) in enumerate(zip(forecasts, tss)):\n",
    "        for j in range(len(forecast.samples[0])):\n",
    "            forecast_data.append({\n",
    "                \"item_id\": i,\n",
    "                \"date\": (series.index[-1] + j + 1).to_timestamp(),\n",
    "                \"forecast_mean\": forecast.mean[j],\n",
    "                \"forecast_quantile_0.1\": forecast.quantile(0.1)[j],\n",
    "                \"forecast_quantile_0.9\": forecast.quantile(0.9)[j]\n",
    "            })\n",
    "\n",
    "    forecast_df = pd.DataFrame(forecast_data)\n",
    "    forecast_df.to_csv(output_path, index=False)\n",
    "    print(f\"Forecast results have been saved to {output_path}\")\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_index = torch.cuda.current_device() if torch.cuda.is_available() else None\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available, using device: {torch.cuda.get_device_name(device_index)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU\")\n",
    "\n",
    "# Set GPU memory usage fraction to 90%\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.set_per_process_memory_fraction(0.9, device_index)\n",
    "\n",
    "# Data loading\n",
    "def load_pkl(pkl_path):\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        return pd.read_pickle(f)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_data = load_pkl(train_pkl_path)\n",
    "\n",
    "# Set up PyTorch DataLoader, enable multi-threaded data loading\n",
    "def from_gluonts(dataset):\n",
    "    for entry in dataset:\n",
    "        target = torch.tensor(entry['target'].tolist(), dtype=torch.float).to(device)\n",
    "        feat_dynamic_real = torch.tensor(entry['feat_dynamic_real'], dtype=torch.float).to(device)\n",
    "        yield target, feat_dynamic_real  # Return target and feat_dynamic_real to ensure data is moved to the GPU\n",
    "\n",
    "train_loader = DataLoader(from_gluonts(train_data), batch_size=512, num_workers=8)\n",
    "\n",
    "# Check current free and total GPU memory\n",
    "if device.type == 'cuda':\n",
    "    free_memory, total_memory = torch.cuda.mem_get_info(device_index)\n",
    "    print(f\"Free memory: {free_memory / 1024**2:.2f} MB, Total memory: {total_memory / 1024**2:.2f} MB\")\n",
    "\n",
    "# Set up DeepAR model\n",
    "estimator = DeepAREstimator(\n",
    "    freq=\"M\",  # Frequency of the time series data (Monthly)\n",
    "    prediction_length=12,  # Prediction length in time points\n",
    "    context_length=99,  # Context length setting in time points\n",
    "    num_layers=10,  # Number of hidden layers in the RNN\n",
    "    hidden_size=1024, # Number of units per hidden layer\n",
    "    batch_size=256,\n",
    "    dropout_rate=0.5,  # Dropout rate, used to prevent overfitting by randomly ignoring some neurons during training\n",
    "    lr=5e-5,  # Learning rate, determines the step size for updating model weights\n",
    "    weight_decay=1e-4,  # Weight decay (L2 regularization), adds a penalty term to the loss function based on the sum of the squares of the weights to prevent overfitting\n",
    "    num_feat_dynamic_real=10, # Number of dynamic features\n",
    "    cardinality=[1,2],  # Number of categories for static features (number of possible values for each category)\n",
    "    scaling=True,  # Enable automatic scaling, standardizes each time series to zero mean and unit variance\n",
    "    trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\",  # Use GPU to accelerate training\n",
    "        \"devices\": 1,  # Use 1 GPU\n",
    "        \"max_epochs\": 200, # Number of training epochs, the number of times the model is trained on the entire dataset\n",
    "    }\n",
    ")\n",
    "\n",
    "# Model training\n",
    "print(\"Training model...\")\n",
    "predictor = None\n",
    "try:\n",
    "    for _ in tqdm(range(1), desc=\"Training model\"):\n",
    "        predictor = estimator.train(training_data=train_data)\n",
    "        if device.type == 'cuda':\n",
    "            free_memory, total_memory = torch.cuda.mem_get_info(device_index)\n",
    "            print(f\"Free memory during training: {free_memory / 1024**2:.2f} MB, Total memory: {total_memory / 1024**2:.2f} MB\")\n",
    "    print(\"Training completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"An exception occurred during training: {e}\")\n",
    "\n",
    "if predictor:\n",
    "    print(\"Saving model...\")\n",
    "    Path(model_save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Saving model to {model_save_path}...\")\n",
    "    predictor.serialize(Path(model_save_path))\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "    try:\n",
    "        print(\"Loading model from disk...\")\n",
    "        predictor = PyTorchPredictor.deserialize(Path(model_save_path))\n",
    "        print(\"Model loaded and moved to GPU.\")\n",
    "\n",
    "        print(\"Starting prediction...\")\n",
    "        forecast_it, ts_it = make_evaluation_predictions(dataset=train_data, predictor=predictor, num_samples=100)\n",
    "        print(\"Prediction completed.\")\n",
    "\n",
    "        forecasts = list(forecast_it)\n",
    "        tss = list(ts_it)\n",
    "        print(f\"Generated {len(forecasts)} forecast results.\")\n",
    "\n",
    "        for i, (forecast, series) in enumerate(zip(forecasts, tss)):\n",
    "            print(f\"Forecast result {i+1}:\")\n",
    "            print(f\"Actual data:\\n{series}\")\n",
    "            print(f\"Forecast mean: {forecast.mean}\")\n",
    "            print(f\"Number of forecast samples: {len(forecast.samples)}\")\n",
    "            print(f\"90% confidence interval: {forecast.quantile(0.1)}, {forecast.quantile(0.9)}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "        # Independent CSV generation process\n",
    "        save_forecasts_to_csv(forecasts, tss, output_csv_path)\n",
    "        \n",
    "        # Start evaluating forecast results\n",
    "        print(\"Starting evaluation of forecast results...\")\n",
    "        evaluator = Evaluator()\n",
    "        try:\n",
    "            for _ in tqdm(range(1), desc=\"Evaluating forecast results\"):\n",
    "                agg_metrics, item_metrics = evaluator(tss, forecasts)\n",
    "            print(\"Evaluation completed.\")\n",
    "\n",
    "            print(\"Aggregate metrics:\")\n",
    "            for key, value in agg_metrics.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An exception occurred during evaluation: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred during prediction or evaluation: {e}\")\n",
    "else:\n",
    "    print(\"Model could not be saved or prediction could not be performed due to training failure.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
